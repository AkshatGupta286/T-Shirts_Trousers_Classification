{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Naive Bayes and Logistic Regression for classification of images as T-Shirts or Trousers\n",
    "\n",
    "### All algorithms are written from scratch and no built in libraries are used for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # used to manipulate mattrices and calculate mean and standard deviation\n",
    "import math # used to calculate log\n",
    "import scipy.io # used to load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Standard Deviation are used as the features for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanFeature(x): # returns the mean value of all the pixels in each image in the sample\n",
    "    \n",
    "    x_mean = np.zeros((0, 1))\n",
    "    \n",
    "    for i in range(x.shape[0]): # sample is iterated through every image\n",
    "        x_mean = np.append(x_mean, np.average(x[i]).reshape(1,1), axis = 0) \n",
    "        # mean of all pixels is taken and value is appended to x_mean array\n",
    "        \n",
    "    return x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStandardDeviationFeature(x): # returns the standard deviation of all the pixels in each image in the sample\n",
    "    \n",
    "    x_std = np.zeros((0, 1))\n",
    "    \n",
    "    for i in range(x.shape[0]): # sample is iterated through every image\n",
    "        x_std = np.append(x_std, np.std(x[i]).reshape(1,1), axis = 0)\n",
    "        # standard deviation of all pixels is taken and value is appended to x_std array\n",
    "        \n",
    "    return x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateClasses(x, y): # separates the samples class wise using the labels\n",
    "    \n",
    "    x_class0 = np.zeros((0,1)) # contains samples of class 0(T-shirts)\n",
    "    x_class1 = np.zeros((0,1)) # contains samples of class 1(Trousers)\n",
    "    \n",
    "    for i in range(x.shape[0]): # sample is iterated through every image\n",
    "\n",
    "        # if label at ith position is 0 then sample at ith position belongs to class 0\n",
    "        if(y[0][i] == 0): \n",
    "            x_class0 = np.append(x_class0, x[i].reshape(1, 1), axis = 0)\n",
    "        else:\n",
    "            x_class1 = np.append(x_class1, x[i].reshape(1, 1), axis = 0)\n",
    "        \n",
    "    return x_class0, x_class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParameters(x): # gets the parameters for a given feature\n",
    "    \n",
    "    mu = np.average(x) \n",
    "    # mu or mean is the mean of all the values of the feature in the given array\n",
    "    \n",
    "    sigma = np.std(x) \n",
    "    # sigma or standard deviation is the standard deviation of all the values of the feature in the given array\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(mu, sigma, x): \n",
    "    # finds the log likelihood of given feature x belonging to a distribution with mu and sigma as parameters\n",
    "    \n",
    "    likelihood = -((math.log(2 * math.pi * math.pow(sigma, 2)) / 2) + (math.pow((x - mu), 2) / (2 * math.pow(sigma, 2))))\n",
    "    # uses the formula of 1-D gaussian distribution to find the likelihood of x belonging to the distribution\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(y_pred, y_actual):\n",
    "    #finds the accuracy of predicted labels with respect to actual labels\n",
    "    \n",
    "    accuracy = (y_pred == y_actual).all(axis = 0).mean() * 100 \n",
    "    # compares all the elements of both the arrays along axis 0 or you can say column wise\n",
    "    # returns 1 if exact match is found and then takes the mean of all the ones \n",
    "    # which ultimately gives us the accuracy of the model\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(data): # naive bayes classifier\n",
    "    \n",
    "    mean_feature = getMeanFeature(data['trX']) \n",
    "    # gets the mean feature vector for training samples\n",
    "    \n",
    "    std_feature = getStandardDeviationFeature(data['trX']) \n",
    "    # gets the standard deviation feature vector for training samples\n",
    "    \n",
    "    class0_mean_feature, class1_mean_feature = separateClasses(mean_feature, data['trY'])\n",
    "    # the mean feature vector is separated based on its label as feature has different parameters for different class\n",
    "\n",
    "    class0_std_feature, class1_std_feature = separateClasses(std_feature, data['trY'])\n",
    "    # the standard deviation feature vector is separated based on its label as feature has different parameters for different class\n",
    "    \n",
    "    class0_mean_feature_mu, class0_mean_feature_sigma = getParameters(class0_mean_feature)\n",
    "    #finds the parameter mu and sigma for mean feature vector of class 0\n",
    "    \n",
    "    class0_std_feature_mu, class0_std_feature_sigma = getParameters(class0_std_feature)\n",
    "    #finds the parameter mu and sigma for standard deviation feature vector of class 0\n",
    "\n",
    "    class1_mean_feature_mu, class1_mean_feature_sigma = getParameters(class1_mean_feature)\n",
    "    #finds the parameter mu and sigma for mean feature vector of class 1\n",
    "\n",
    "    class1_std_feature_mu, class1_std_feature_sigma = getParameters(class1_std_feature)\n",
    "    #finds the parameter mu and sigma for standard deviation feature vector of class 1\n",
    "\n",
    "    # at this point we have the trained model and we will check its performance using the test data\n",
    "    \n",
    "    py_1 = np.average(data['trY']) # finding probability of label 1 which is the mean of training label vector\n",
    "    py_0 = 1 - py_1 # finding probability of label 0 which is (1 - probability of label 1)\n",
    "    \n",
    "    predicted_labels = np.zeros((1,0)) # initializing array to store predicted labels\n",
    "\n",
    "    for i in range(data['tsX'].shape[0]): # prediction loop\n",
    "\n",
    "        test_mean_feature = np.average(data['tsX'][i]) # finding the mean feature of test sample\n",
    "        test_std_feature = np.std(data['tsX'][i]) # finding the standard deviation feature of test sample\n",
    "        \n",
    "        p_label0 = gaussian(class0_mean_feature_mu, class0_mean_feature_sigma, test_mean_feature) + gaussian(class0_std_feature_mu, class0_std_feature_sigma, test_std_feature) + math.log(py_0)\n",
    "        #finding the probability of label 0 for the given test sample\n",
    "\n",
    "        p_label1 = gaussian(class1_mean_feature_mu, class1_mean_feature_sigma, test_mean_feature) + gaussian(class1_std_feature_mu, class1_std_feature_sigma, test_std_feature) + math.log(py_1)\n",
    "        #finding the probability of label 1 for the given test sample\n",
    "\n",
    "        # if probability of label 0 is greater than label 1, the predicted label is 1 and vice versa\n",
    "        if(p_label0 > p_label1): \n",
    "            predicted_labels = np.append(predicted_labels, [[0]], axis = 1)\n",
    "        else:\n",
    "            predicted_labels = np.append(predicted_labels, [[1]], axis = 1)\n",
    "        \n",
    "    \n",
    "    actual_labels = data['tsY'] # actual labels of test data\n",
    "    \n",
    "    accuracy = getAccuracy(predicted_labels, actual_labels) # getting accuracy of the model.\n",
    "        \n",
    "    print(\"Accuracy of Naive-Bayes Classifier:\", accuracy)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(data): # logistic regression classifier\n",
    "    \n",
    "    x0 = np.ones((12000, 1)) # vector of ones for w0\n",
    "    mean_feature = getMeanFeature(data['trX']) # vector of mean feature of training samples\n",
    "    std_feature = getStandardDeviationFeature(data['trX']) # vector of standard deviation feature of training samples\n",
    "\n",
    "    x = np.concatenate((x0, mean_feature, std_feature), axis = 1) # concatenating the three vectors\n",
    "    y = data['trY'] # training labels\n",
    "    w = np.array([[0.001, 0.001, 0.001]]) # initial random weights\n",
    "    lr = .001 # learning rate\n",
    "    epochs = 1000 # number of iterations\n",
    "    \n",
    "    current_epoch = 0\n",
    "    \n",
    "    # training of the model\n",
    "    while current_epoch != epochs: \n",
    "        z = np.divide(np.exp(np.matmul(w, x.transpose())), (np.exp(np.matmul(w, x.transpose())) + 1)) \n",
    "        # sigmoid vector or predicted labels using training samples and current weights \n",
    "        w = w + (lr * np.matmul((y - z), x)) # updating weights using gradient ascent approach   \n",
    "        current_epoch += 1\n",
    "        \n",
    "    # after this loop we have the trained model and we will check its performance using the test data\n",
    "    \n",
    "    # creating the test set\n",
    "    test_x0 = np.ones((2000, 1))  # vector of ones for w0\n",
    "    test_mean_feature = getMeanFeature(data['tsX']) # vector of mean feature of test samples\n",
    "    test_std_feature = getStandardDeviationFeature(data['tsX']) # vector of standard deviation feature of test samples\n",
    "\n",
    "    test_x = np.concatenate((test_x0, test_mean_feature, test_std_feature), axis = 1) # concatenating the three vectors\n",
    "    \n",
    "    predicted_labels = np.matmul(w, test_x.transpose()) \n",
    "    # predicting the labels for test data using the trained weights w\n",
    "\n",
    "    # the values we have are not actually 0 and 1, they are values in between 0 and 1\n",
    "    # so we use a threshold to convert those values into labels. In this case the threshold is 0.5\n",
    "    for i in range(predicted_labels.shape[1]):\n",
    "        if predicted_labels[0][i] < 0.5:\n",
    "            predicted_labels[0][i] = 0\n",
    "        else:\n",
    "            predicted_labels[0][i] = 1\n",
    "            \n",
    "    actual_labels = data['tsY'] # actual labels of test data\n",
    "    \n",
    "    accuracy = getAccuracy(predicted_labels, actual_labels) # getting accuracy of the model.\n",
    "    \n",
    "    print(\"Accuracy of Logistic Regression Classifier:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive-Bayes Classifier: 83.15\n",
      "\n",
      "\n",
      "Accuracy of Logistic Regression Classifier: 92.2\n"
     ]
    }
   ],
   "source": [
    "# main function\n",
    "\n",
    "data = scipy.io.loadmat('Datasets/Tshirts_Trousers.mat') # loading the data set\n",
    "naive_bayes(data) # calling naive bayes classifier for the data\n",
    "logistic_regression(data) # calling logistic regression classifier for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
